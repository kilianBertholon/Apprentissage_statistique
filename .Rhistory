knitr::opts_chunk$set(echo = TRUE)
library(readODS)
data <- read.ods("data_bmx.ods")
library(readODS)
data <- read_ods("data_bmx.ods")
library(readODS)
data <- read_ods("data_bmx.ods")
library(readODS)
data <- read_ods("/data_bmx.ods")
data <- read_ods("data_bmx.ods")
View(data)
data <- data[,-1]
View(data)
knitr::opts_chunk$set(echo = TRUE)
library(readODS)
data <- read_ods("data_bmx.ods")
data <- data[,-1]
View(data)
library(readODS)
data <- read_ods("data/data_bmx.ods")
data <- data[,-1]
View(data)
knitr::opts_chunk$set(echo = TRUE)
data$Position_Start[data$Position_Start == -1] <- NA
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start), ]
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
depart_arrivee <- data[c("Position_Start", "Temps_Final")]
View(data)
View(depart_arrivee)
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
depart_arrivee <- data[c("Position_Start", "Classement_Final")]
View(data)
depart_arrivee <- data[c("Position_Start", "Classement_final")]
View(depart_arrivee)
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
depart_arrivee <- data[c("Position_Start", "Classement_final")]
depart_arrivee$Position_Start <- as.numeric(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.numeric(depart_arrivee$Classement_final)
depart_arrivee$Position_Start <- as.factor(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.factor(depart_arrivee$Classement_final)
summary(depart_arrivee)
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
depart_arrivee <- data[c("Position_Start", "Classement_final")]
niveaux_ordre <- as.character(1:8)
depart_arrivee$Position_Start <- as.numeric(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.numeric(depart_arrivee$Classement_final)
depart_arrivee$Position_Start <- as.factor(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.factor(depart_arrivee$Classement_final, levels = niveaux_ordre)
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
depart_arrivee <- data[c("Position_Start", "Classement_final")]
niveaux_ordre <- as.character(1:8)
depart_arrivee$Position_Start <- as.numeric(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.numeric(depart_arrivee$Classement_final)
depart_arrivee$Position_Start <- as.factor(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- factor(depart_arrivee$Classement_final, levels = niveaux_ordre)
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
# Afficher le tableau
print(pourcentages)
pourcentages <- data.frame(pourcentages)
View(pourcentages)
pourcentages
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages <- round(pourcentage, 2)
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages <- round(pourcentages, 2)
pourcentages
14639/8
data_final <- data |> filter(Manche == 'Demi-final' |
Manche == 'Final' |
Manche == 'Quart-final')
data_final <- data_final[c("Position_Start", "Classement_final")]
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
data_final <- data |> filter(Manche == 'Demi-final' |
Manche == 'Final' |
Manche == 'Quart-final')
depart_arrivee <- data[c("Position_Start", "Classement_final")]
data_final <- data_final[c("Position_Start", "Classement_final")]
niveaux_ordre <- as.character(1:8)
depart_arrivee$Position_Start <- as.numeric(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.numeric(depart_arrivee$Classement_final)
depart_arrivee$Position_Start <- as.factor(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- factor(depart_arrivee$Classement_final, levels = niveaux_ordre)
data_final$Position_Start <- as.numeric(data_final$Position_Start)
data_final$Classement_final <- as.numeric(data_final$Classement_final)
data_final$Position_Start <- as.factor(data_final$Position_Start)
data_final$Classement_final <- factor(data_final$Classement_final, levels = niveaux_ordre)
tableau_contingence <- table(data_final$Position_Start, data_final$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages <- round(pourcentages, 2)
pourcentages
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages <- round(pourcentages, 2)
tableau_contingence <- table(data_final$Position_Start, data_final$Classement_final)
# Calculer les pourcentages par ligne
pourcentages2 <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages2 <- round(pourcentages, 2)
pourcentages
pourcentages2
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
data_final <- data |> filter(Manche == 'Demi-final' |
Manche == 'Final' |
Manche == 'Quart-final')
depart_arrivee <- data[c("Position_Start", "Classement_final")]
data_final <- data_final[c("Position_Start", "Classement_final")]
niveaux_ordre <- as.character(1:8)
depart_arrivee$Position_Start <- as.numeric(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.numeric(depart_arrivee$Classement_final)
depart_arrivee$Position_Start <- as.factor(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- factor(depart_arrivee$Classement_final, levels = niveaux_ordre)
data_final$Position_Start <- as.numeric(data_final$Position_Start)
data_final$Classement_final <- as.numeric(data_final$Classement_final)
data_final$Position_Start <- as.factor(data_final$Position_Start)
data_final$Classement_final <- factor(data_final$Classement_final, levels = niveaux_ordre)
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages <- round(pourcentages, 2)
tableau_contingence2 <- table(data_final$Position_Start, data_final$Classement_final)
# Calculer les pourcentages par ligne
pourcentages2 <- prop.table(tableau_contingence2, margin = 1) * 100
pourcentages2 <- round(pourcentages, 2)
pourcentages
pourcentages2
tableau_contingence2 <- table(data_final$Position_Start, data_final$Classement_final)
# Calculer les pourcentages par ligne
pourcentages2 <- prop.table(tableau_contingence2, margin = 1) * 100
pourcentages2 <- round(pourcentages, 2)
tableau_contingence2 <- table(data_final$Position_Start, data_final$Classement_final)
# Calculer les pourcentages par ligne
pourcentages2 <- prop.table(tableau_contingence2, margin = 1) * 100
pourcentages2 <- round(pourcentages2, 2)
pourcentages
pourcentages2
difference <- pourcentages2 - pourcentages
difference <- pourcentages2 - pourcentages
difference
2948/8
esquisse:::esquisser()
View(data)
View(data_final)
knitr::opts_chunk$set(echo = TRUE)
# Charger les packages
library(tidymodels)
# Charger les données (remplacez "votre_dataset.csv" par le nom de votre fichier de données)
# Spécifier les colonnes prédictives et la colonne de la variable dépendante
predictors <- c("Position_Start", "Rang_T1", "Rang_T2", "Rang_T3", "Rang_T4")  # Remplacez par vos noms de variables prédictives
response <- "Classement_final"  # Remplacez par le nom de votre variable dépendante
# # Diviser les données en ensembles d'entraînement et de test
# set.seed(123)  # Pour la reproductibilité
# split <- initial_split(data, prop = 0.7, strata = response)
# train_data <- training(split)
# test_data <- testing(split)
#
# # Prétraitement des données
# # (Cela dépendra de la nature de vos données et des transformations nécessaires)
# preprocess <- recipe(formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data) %>%
#   step_...  # Ajoutez les étapes de prétraitement nécessaires (ex. imputation, transformation, etc.)
#
# # Définir le modèle de régression logistique
# logistic_model <- logistic_reg() %>%
#   set_engine("glm")  # Vous pouvez également utiliser "glmnet" pour la régularisation L1/L2
#
# # Créer le workflow avec les étapes de prétraitement et le modèle
# workflow <- workflow() %>%
#   add_recipe(preprocess) %>%
#   add_model(logistic_model)
#
# # Entraîner le modèle
# trained_model <- fit(workflow, data = train_data)
#
# # Faire des prédictions sur l'ensemble de test
# predictions <- predict(trained_model, new_data = test_data)
#
# # Évaluer les performances du modèle
# conf_mat <- conf_mat(predictions, truth = !!sym(response), estimate = !!sym("`.pred_class`"))
# print(conf_mat)
# Charger les packages
library(tidymodels)
# Charger les données (remplacez "votre_dataset.csv" par le nom de votre fichier de données)
# Spécifier les colonnes prédictives et la colonne de la variable dépendante
predictors <- c("Position_Start", "Rang_T1", "Rang_T2", "Rang_T3", "Rang_T4")  # Remplacez par vos noms de variables prédictives
response <- "Classement_final"  # Remplacez par le nom de votre variable dépendante
# # Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
split <- initial_split(data, prop = 0.7, strata = response)
train_data <- training(split)
test_data <- testing(split)
#
# # Prétraitement des données
# # (Cela dépendra de la nature de vos données et des transformations nécessaires)
# preprocess <- recipe(formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data) %>%
#   step_...  # Ajoutez les étapes de prétraitement nécessaires (ex. imputation, transformation, etc.)
#
# # Définir le modèle de régression logistique
# logistic_model <- logistic_reg() %>%
#   set_engine("glm")  # Vous pouvez également utiliser "glmnet" pour la régularisation L1/L2
#
# # Créer le workflow avec les étapes de prétraitement et le modèle
# workflow <- workflow() %>%
#   add_recipe(preprocess) %>%
#   add_model(logistic_model)
#
# # Entraîner le modèle
# trained_model <- fit(workflow, data = train_data)
#
# # Faire des prédictions sur l'ensemble de test
# predictions <- predict(trained_model, new_data = test_data)
#
# # Évaluer les performances du modèle
# conf_mat <- conf_mat(predictions, truth = !!sym(response), estimate = !!sym("`.pred_class`"))
# print(conf_mat)
# Charger les packages
library(tidymodels)
# Charger les données (remplacez "votre_dataset.csv" par le nom de votre fichier de données)
# Spécifier les colonnes prédictives et la colonne de la variable dépendante
predictors <- c("Position_Start", "Rang_T1", "Rang_T2", "Rang_T3", "Rang_T4")  # Remplacez par vos noms de variables prédictives
response <- "Classement_final"  # Remplacez par le nom de votre variable dépendante
# # Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
split <- initial_split(data, prop = 0.7, strata = response)
train_data <- training(split)
test_data <- testing(split)
# Prétraitement des données
# (Cela dépendra de la nature de vos données et des transformations nécessaires)
preprocess <- recipe(formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data)
# Définir le modèle de régression logistique
logistic_model <- logistic_reg() %>%
set_engine("glm")  # Vous pouvez également utiliser "glmnet" pour la régularisation L1/L2
# Créer le workflow avec les étapes de prétraitement et le modèle
workflow <- workflow() %>%
add_recipe(preprocess) %>%
add_model(logistic_model)
# Entraîner le modèle
trained_model <- fit(workflow, data = train_data)
# Faire des prédictions sur l'ensemble de test
predictions <- predict(trained_model, new_data = test_data)
# Évaluer les performances du modèle
conf_mat <- conf_mat(predictions, truth = !!sym(response), estimate = !!sym("`.pred_class`"))
install.packages("dotwhisker")
# Spécifier les colonnes prédictives et la colonne de la variable dépendante
predictors <- c("Position_Start", "Rang_T1", "Rang_T2", "Rang_T3", "Rang_T4")  # Remplacez par vos noms de variables prédictives
class(data$Classement_final)
library(dplyr)
data$Position_Start[data$Position_Start == -1] <- NA
# Sélectionner les lignes sans NA dans la colonne spécifiée
data <- data[complete.cases(data$Position_Start) & !grepl("DNS|DNF", data$Temps_Final), ]
data_final <- data |> filter(Manche == 'Demi-final' |
Manche == 'Final' |
Manche == 'Quart-final')
depart_arrivee <- data[c("Position_Start", "Classement_final")]
data_final <- data_final[c("Position_Start", "Classement_final")]
niveaux_ordre <- as.character(1:8)
depart_arrivee$Position_Start <- as.numeric(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- as.numeric(depart_arrivee$Classement_final)
depart_arrivee$Position_Start <- as.factor(depart_arrivee$Position_Start)
depart_arrivee$Classement_final <- factor(depart_arrivee$Classement_final, levels = niveaux_ordre)
data_final$Position_Start <- as.numeric(data_final$Position_Start)
data_final$Classement_final <- as.numeric(data_final$Classement_final)
data_final$Position_Start <- as.factor(data_final$Position_Start)
data_final$Classement_final <- factor(data_final$Classement_final, levels = niveaux_ordre)
# Tableau de contingence
tableau_contingence <- table(depart_arrivee$Position_Start, depart_arrivee$Classement_final)
# Calculer les pourcentages par ligne
pourcentages <- prop.table(tableau_contingence, margin = 1) * 100
pourcentages <- round(pourcentages, 2)
tableau_contingence2 <- table(data_final$Position_Start, data_final$Classement_final)
# Calculer les pourcentages par ligne
pourcentages2 <- prop.table(tableau_contingence2, margin = 1) * 100
pourcentages2 <- round(pourcentages2, 2)
difference <- pourcentages2 - pourcentages
class(data$Classement_final)
# Charger les packages
library(tidymodels)
library(dotwhisker)  # for visualizing regression results
# Charger les données (remplacez "votre_dataset.csv" par le nom de votre fichier de données)
# Spécifier les colonnes prédictives et la colonne de la variable dépendante
predictors <- c("Position_Start", "Rang_T1", "Rang_T2", "Rang_T3", "Rang_T4")  # Remplacez par vos noms de variables prédictives
response <- "Classement_final"  # Remplacez par le nom de votre variable dépendante
# # Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
split <- initial_split(data, prop = 0.7, strata = response)
train_data <- training(split)
test_data <- testing(split)
# Prétraitement des données
# (Cela dépendra de la nature de vos données et des transformations nécessaires)
preprocess <- recipe(formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data)
# Définir le modèle de régression logistique
logistic_model <- ordinal_reg() %>%
set_engine("clm")
??ordinal_reg
# Charger les packages
library(tidymodels)
library(dotwhisker)  # for visualizing regression results
data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")] <- lapply(data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")], as.numeric)
data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")] <- lapply(data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")], function(x) factor(x, levels = 1:8, ordered = TRUE))
# Charger les données (remplacez "votre_dataset.csv" par le nom de votre fichier de données)
# Spécifier les colonnes prédictives et la colonne de la variable dépendante
predictors <- c("Position_Start", "Rang_T1", "Rang_T2", "Rang_T3", "Rang_T4")  # Remplacez par vos noms de variables prédictives
response <- "Classement_final"  # Remplacez par le nom de votre variable dépendante
# # Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
split <- initial_split(data, prop = 0.7, strata = response)
train_data <- training(split)
test_data <- testing(split)
# Prétraitement des données
# (Cela dépendra de la nature de vos données et des transformations nécessaires)
preprocess <- recipe(formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data)
# Définir le modèle de régression logistique
logistic_model <- ordinal_reg() %>%
set_engine("clm")
# Charger les packages
library(tidymodels)
library(dotwhisker)  # for visualizing regression results
library(ordinal)
data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")] <- lapply(data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")], as.numeric)
data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")] <- lapply(data[, c("Classement_final", "Position_Start", "Rang_T1", "Rang_T2", "Rang_T3")], function(x) factor(x, levels = 1:8, ordered = TRUE))
# Charger les données (remplacez "votre_dataset.csv" par le nom de votre fichier de données)
# Spécifier les colonnes prédictives et la colonne de la variable dépendante
predictors <- c("Position_Start", "Rang_T1", "Rang_T2", "Rang_T3", "Rang_T4")  # Remplacez par vos noms de variables prédictives
response <- "Classement_final"  # Remplacez par le nom de votre variable dépendante
# # Diviser les données en ensembles d'entraînement et de test
set.seed(123)  # Pour la reproductibilité
split <- initial_split(data, prop = 0.7, strata = response)
train_data <- training(split)
test_data <- testing(split)
# Prétraitement des données
# (Cela dépendra de la nature de vos données et des transformations nécessaires)
preprocess <- recipe(formula = as.formula(paste(response, "~", paste(predictors, collapse = "+"))), data = train_data)
# Définir le modèle de régression logistique
logistic_model <- ordinal_reg() %>%
set_engine("clm")
