---
title: "Projet_AS"
author: "kilian_ber"
date: "2023-11-16"
output: html_document
---

# Projet Apprentissage statistique

Fontaine Aymeric

Tavian Mattéo

Bertholon Kilian

## Etape 1 : Explication sur les données traitées.

Nous avons choisi de travailler sur des données de football. Ne trouvant pas de jeu de données intéresant. Nous avons donc choisi décidé de web-scrapper des données issus d'un site Internet. Nous avons décidé de travailer sur le site : <https://redscores.com/fr/football-stats>.

A l'aide d'un code Javascript construit pour cela nous avons pu récupérer les données issues de 42000 joueurs sur plus de 5 saisons (sur les 10 plus grands championnats mondiaux ainsi que 5 championnats de 2ème division.

Le code Javascript est disponible dans le dossier code Javascript.

Pour chacun des joueurs on dispose d'informations sur ses performances au court de l'année :

-   Son nom

-   Son poste

-   Son club

-   Son Age

-   Le nombre de Minutes jouées dans l'années

-   Le nombre d'apparitions (en match)

-   Le nombre de but qu'il a inscrit

-   Le nombre de passe décisive qu'il a délivré

-   Sa note moyenne sur l'ensemble de l'année

-   Le nombre de tirs moyen par match

-   Le nombre de dribbles moyen par match

-   Le pourcentage de passes réussis par match

-   La moyenne de passe clé par match

-   Le pourcentage de centre réussis

-   Le nombre de dégagemetn par match

-   Le nombre d'interception moyen par match

-   Le nombre de tacle moyen par match

-   Le nombre de Tir bloqués moyen par match

-   Le nombre de dribbles subis moyen par match

-   Le nombre de fautes moyen par match

-   Le nombre de tacles moyen recu par match

-   Le nombre de Hors-jeu moyen par match

-   L'année de références des stastiques

## Etape 2 : Import des données et Pré-traitement

```{r}
#### Chargement des packages ####

library(jsonlite)
library(tidyr)
library(ggplot2)
library(dplyr)
library(corrplot)
library(ggraph)
library(tidymodels)
library(xgboost)
library(doParallel)
library(vip)
library(plotly)
library(yardstick)


```

Dans cette partie, nous effectuerons les modifications nécessaires pour créer le dataframe que l'on utilisera à partir des JSON crée précédamment par le scrapping

```{r}

#Indiquer les années disponibles
year_available <- 2019:2023

#Boucle de création du dataframe à partir des nom de fichiers
for (annee in year_available) {
  fichier_data <- paste0("resultat_football_", annee, ".json")
  data <- fromJSON(fichier_data)
  
  top10 <- data$Top10_championnat
  hors_top10 <- data$Autres
  
  data <- rbind(top10, hors_top10)
  data = data[-1]
  
  data <- separate(data, info, into = c("Poste", "Club", "Age"), sep = ",\\s*")
  
  data$Age <- sub("yrs", "", data$Age)
  data$Passes_perc <- (as.numeric(sub("%", "", data$Passes_perc)))
  
  data <- data %>% rename(Apparences = CartonJaune)
  
  cols_to_convert <- c("Age", "minJ", "Apparences", "But", "PasseDecisive", "Note", "Tirs",
                       "Dribbles", "moy_passes", "centre_perc", "degagement", "interception",
                       "tacle", "tirsBloques", "driblesSubis", "fautes", "TaclesRecu", "HorsJeu")
  
  data[, cols_to_convert] <- lapply(data[, cols_to_convert], function(x) as.numeric(gsub("'", "", x)))
  
  data$Annee <- as.character(annee)
  
  assign(paste0("data_", annee), data)
}


all_data <- rbind(data_2023, data_2022, data_2021, data_2020, data_2019)

summary(all_data)

```

## Etape 3 : Première analyses visuelles sur les données

### Analyse des distributions variables par variables

#### a) Répartition par postes

```{r}
#Les postes étaient avant des postes précis (milieu offensif droit par exemple. Par soucis de compréhension nous remplacons ces postes par 4 modalités (Gardien, défenseur, milieu et attaquant))
all_data <- all_data %>%
  mutate(Poste_global = case_when(
    Poste %in% c("AM", "CF", "LW", "RW") ~ "Attaquant",
    Poste %in% c("CB", "DF", "LB", "RB") ~ "Défenseur",
    Poste %in% c("CM", "DM", "LM", "MF", "RM") ~ "Milieu",
    Poste == "GK" ~ "Gardien",
    Poste == '' ~ NA,
    TRUE ~ "Autre"
  ))
ggplot(all_data, aes(x = Poste_global)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution des postes des joueurs de foot",
       x = "Poste",
       y = "Nombre de joueurs")



```

#### b) Age

```{r}
# Créez un histogramme de l'âge
ggplot(all_data, aes(x = Age)) +
  geom_histogram(binwidth = 1, fill = "cyan", color = "black", alpha = 0.7) +
  labs(title = "Distribution de l'âge des joueurs", x = "Âge", y = "Fréquence")
```

#### c) But

```{r}

all_data$Poste_global <- factor(all_data$Poste_global, levels = c("Gardien", "Défenseur", "Milieu", "Attaquant", "NA"))

ggplot(all_data, aes(x = Poste_global, y = But)) +
  geom_boxplot(fill = "skyblue", color = "black") +  
  labs(title = "Distribution des buts par poste global",
       x = "Poste Global",
       y = "Buts")
```

#### d) Passes décisives

```{r}
# Créez un boxplot pour la distribution des passes décisives en fonction du poste global
ggplot(all_data, aes(x = Poste_global, y = PasseDecisive, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des passes décisives en fonction du poste global", x = "Poste global", y = "Passe décisives") +
  scale_fill_brewer(palette = "Set3")  # Vous pouvez changer la palette de couleurs selon vos préférences
```

#### e) Minutes jouées

```{r}
Min_joue_poste<- ggplot(all_data, aes(x = Poste_global, y = minJ, fill = Poste_global)) +
  geom_boxplot() +  # Utiliser un boxplot pour la distribution
  labs(title = "Distribution des Minutes jouées par poste ",
       x = "Poste ",
       y = "Minutes jouées")

# Afficher le graphique
print(Min_joue_poste)
```

#### f) Apparitions

```{r}
# Créez un boxplot pour la distribution des passes décisives en fonction du poste global
ggplot(all_data, aes(x = Poste_global, y = Apparences, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des apparitions des joueurs en fonction du poste global", x = "Poste global", y = "Apparitions") +
  scale_fill_brewer(palette = "Set3")  # Vous pouvez changer la palette de couleurs selon vos préférences
```

#### g) Note

```{r}
# Créez un boxplot pour la distribution des Notes fonction du poste global
ggplot(all_data, aes(x = Poste_global, y = Note, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des notes des joueurs en fonction du poste global", x = "Poste global", y = "Note") +
  scale_fill_brewer(palette = "Set3")  # Vous pouvez changer la palette de couleurs selon vos préférences
```

#### h) Tirs

```{r}
ggplot(all_data, aes(x = Poste_global, y = Tirs, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des tirs des joueurs en fonction du poste global", x = "Poste global", y = "Tirs") +
  scale_fill_brewer(palette = "Set3") 
```

#### i) Dribbles

```{r}
ggplot(all_data, aes(x = Poste_global, y = Dribbles , fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des dribbles des joueurs en fonction du poste global", x = "Poste global", y = "Dribbles") +
  scale_fill_brewer(palette = "Set3")
```

#### j) Passes Pourcentages

```{r}
ggplot(all_data, aes(x = Poste_global, y = Passes_perc , fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des pourcentages de passes réussies des joueurs en fonction du poste global", x = "Poste global", y = "Pourcentage de passes réussies") +
  scale_fill_brewer(palette = "Set3") 
```

#### k) Moyenne passe clé

```{r}
ggplot(all_data, aes(x = Poste_global, y = moy_passes , fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des moyennes des passes clées des joueurs en fonction du poste global", x = "Poste global", y = "Moyenne de passes clées par match") +
  scale_fill_brewer(palette = "Set3")  
```

#### l) Centre pourcentage

```{r}
ggplot(all_data, aes(x = Poste_global, y = centre_perc , fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des pourcentages de centres réussies des joueurs en fonction du poste global", x = "Poste global", y = "Pourcentage de centres réussis") +
  scale_fill_brewer(palette = "Set3") 
```

#### m) Dégagement

```{r}
ggplot(all_data, aes(x = Poste_global, y = degagement , fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des dégagements des joueurs en fonction du poste global", x = "Poste global", y = "Dégagements") +
  scale_fill_brewer(palette = "Set3") 
```

On voit que tout les boxplots quelque soit le poste sont situées à 0. Cela signifie que toute la colonne "degagement" du jeu de données est constituée de 0. Cette variable n'est donc pas nécessaire, on peut la supprimer.

```{r}
all_data <- subset(all_data, select = -degagement)
```

#### n) Interception

```{r}
ggplot(all_data, aes(x = Poste_global, y = interception , fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Distribution des interceptions des joueurs en fonction du poste global", x = "Poste global", y = "interception") +
  scale_fill_brewer(palette = "Set3")
```

#### o) Tacles recus

```{r}
ggplot(all_data, aes(x = Poste_global, y = TaclesRecu, fill = Poste_global)) +
  geom_boxplot() +  
  labs(title = "Tacles recus par postes",
       x = "Postes ",
       y = "Tacles recus")
```

#### p) Tirs bloques

```{r}
ggplot(all_data, aes(x = Poste_global, y = tirsBloques, fill = Poste_global)) +
  geom_boxplot() + 
  labs(title = "Tirs bloqués par par postes",
       x = "Postes ",
       y = "Tirs bloqués")


```

#### q) Dribles subis

```{r}
ggplot(all_data, aes(x = Poste_global, y = driblesSubis, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Dribles subis par par postes",
       x = "Postes ",
       y = "Dribles Subis")
```

#### r) Fautes commises moyennes par match

```{r}
ggplot(all_data, aes(x = Poste_global, y = fautes, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Fautes par postes",
       x = "Postes",
       y = "Fautes moyenne par match")
```

#### s) Tacles recu

```{r}
ggplot(all_data, aes(x = Poste_global, y = TaclesRecu, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Tacles recu par postes",
       x = "Poste ",
       y = "Tacles recu")
```

#### t) Hors jeu

```{r}
ggplot(all_data, aes(x = Poste_global, y = HorsJeu, fill = Poste_global)) +
  geom_boxplot() +
  labs(title = "Hors jeu par postes",
       x = "Poste ",
       y = "Hors jeu")

```

On voit ici que les Hors jeu sont nul pour chacunes des modalités. On peut donc substituer cette colonne dans le cas ou nos données ne seront pas completées par de nouvelles données comportant des hors-jeu

```{r}
all_data <- subset(all_data, select = -HorsJeu)
```

#### u) Annee

```{r}
table_annee <- data.frame(table(all_data$Annee))

ggplot(table_annee, aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Observation par années",
       x = "Année",
       y = "Observations")
```

### Analyse des corrélations globales

On peut penser que certaines variables peuvent être corrélées. Selon le modèle que l'on utilise ca pourrait éventuellement nous poser problèmes. On va donc étudier cela.

Nous avons seulement des variables quantitatives --\> corrélations de Pearson

```{r}

# Sélectionner seulement les colonnes avec des variables quantitatives
variables_quantitatives <- all_data %>%
  select_if(is.numeric)

variables_quantitatives <- na.omit(variables_quantitatives)

# Calculer la matrice de corrélation
matrice_correlation <- cor(variables_quantitatives, use = "complete.obs")

# Afficher une heatmap avec corrplot
corrplot(matrice_correlation, method = "color", type = "lower", diag = FALSE, col = COL2('RdYlBu', 10))

```

Quelques variables paraissent un peu corrélées :

-   Minutes jouées avec le nombre d'apparitions ( ce qui parait logique )

-   Le nombre de but avec le nombre de tirs

-   Le nombre de passe clés avec le nombre de passes décisives

-   Le pourcentage de passes avec le nombre d'apparritions

-   Le nombre d'interception avec le nombre de tacles

## Etape 4 : Identification des probématiques potentielles :

Dans le cadre du footbal, plusieurs problématiques peuvent se poser devant nous avec les données dont nous disposons :

1)  Essayer de calculer la note des joueurs à partir de leurs statistiques

2)  Essayer d'identifier des performances futures à partir des performances passées

3)  Essayer de confirmer des choix de l'entraineurs (visualisables à partir de apparitions et des minutes jouées)

4)  Essayer d'identifier des critères de performances pour chacuns des postes

# 1) Note des joueurs

Le site sur lesquel nous avons recolté nos données permet d'obtenir les notes de chaque joueurs. Nous aimerions pouvoir recalculer les notes de chacun des joueurs à partir de leurs statistiques.

Cependant, nos connaissances de la disciplines nous indiquent que les notes des joueurs à partir des statistiques seront dépendantes du postes (un attaquant qui effectue plus de tirs sera avantagé car c'est ce qu'on lui demande)

L'ensemble de nos variables sont quantitatives : Nous allons donc pouvoir essayer plusieurs modèles différents afin d'estimer aux plus justes les notes des joueurs.

Dans un premier temps, il va donc falloir préparer nos données pour rassembler les joueurs par postes.

Notre démarche s'effectuera de tel sorte :

1)  Préparer nos donnnées

2)  Comparer les différents modèles vus en cours sur l'ensemble de nos données ( SVM, reg LASSO, reg RIDGE, reg Linéaire, XGboost, Foret aléatoires).

-   Les otpimisations des hyper-paramètres seront effectuées sur chacun des mdoèles

3)  Sélectionner le modèle qui semble le plus efficace

4)  Essayer d'obtimiser les différentes variables pour augmenter la prédiction finale

## Pré-traitement des données

### Rassembler les joueurs par postes

```{r}

Gardien <- all_data |> filter(Poste_global == "Gardien")
Defenseur <- all_data |> filter(Poste_global == "Défenseur")
Milieu <- all_data |> filter(Poste_global == "Milieu")
Attaquant <- all_data |> filter(Poste_global == "Attaquant")

```

### Etudier la distribution des notes par postes

```{r}
density <- ggplot(all_data, aes(Note, color = Poste_global)) + geom_density()
density
```

On semble plutot suivre une loin normale sur chacun des notes des différents postes

## Utilisation des différents algorithmes

### a) XGBoost

### Attaquant

```{r}
all_data_attaquant <- subset(Attaquant, select = -c(nom, Poste, Club, Annee, Poste_global))
all_data_attaquant <- na.omit(all_data_attaquant, cols = "Note")

#Diviser en entrainement et test
set.seed(123)
data_split_att <- initial_split(all_data_attaquant, prop = 0.75, strata = Note)
data_train_att <- training(data_split_att)
data_test_att <- testing(data_split_att)

#Préparation des données 
variable_a_tester_xg <- c("Age","minJ","Apparences","But","PasseDecisive","Tirs","Dribbles","Passes_perc","moy_passes","centre_perc","interception","tacle","tirsBloques","driblesSubis","fautes","TaclesRecu")
recipe_xg_att <- recipe(Note ~ ., data = data_train_att) |>
  update_role(all_of(variable_a_tester_xg), new_role = "predictor") |>
  step_normalize(all_predictors())

xgb_model_att <-
  boost_tree(
    trees = 1000,
    stop_iter=20,
    min_n = 1,
    tree_depth = tune(),
    learn_rate = tune()
  ) |>
  set_mode("regression") |>
  set_engine("xgboost")

xgb_wf_att <- workflow() |>
  add_recipe(recipe_xg_att) |>
  add_model(xgb_model_att)

play_samples_cv_att <- vfold_cv(data_train_att,v=3,repeats=1,strata="Note")

xgb_grid <- expand.grid(tree_depth=c(1,2,3,4,5),learn_rate=c(0.0205,0.0210, 0.215,0.220))

xgb_3fold_att <- xgb_wf_att |>
  tune_grid(resamples=play_samples_cv_att,grid=xgb_grid,
            metrics=metric_set(mae))

xgb_3fold_att |> autoplot()

best_par_att <- xgb_3fold_att |>
  select_best()

final_xgb_att <- xgb_wf_att |> 
  finalize_workflow(best_par_att) |>
  fit(data = data_train_att)

pred_att <- final_xgb_att |>
  predict(new_data=data_test_att)


data_test_att_fin <- data_test_att |> select(Note)
data_test_att_fin_2 <- cbind(pred_att, data_test_att_fin)

data_test_att_fin_2$Difference <- data_test_att_fin_2$Note - data_test_att_fin_2$.pred
data_test_att_fin_2$DifferenceAbs <- abs(data_test_att_fin_2$Note - data_test_att_fin_2$.pred)


# Calculer la médiane et les intervalles de confiance
median_diff_att <- median(data_test_att_fin_2$Difference)
ci_low_att <- quantile(data_test_att_fin_2$Difference, 0.025)
ci_high_att <- quantile(data_test_att_fin_2$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
gg_plot_att <- ggplot(data_test_att_fin_2, aes(x = rownames(data_test_att_fin_2), y = Difference, color = Note)) +
  geom_point() +
  geom_hline(yintercept = median_diff_att, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low_att, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high_att, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction XGboost sur Attaquant",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

gg_plot_att

R2_att_xg <- 1 - sum((data_test_att_fin_2$Note - data_test_att_fin_2$.pred)^2) / sum((data_test_att_fin_2$Note - mean(data_test_att_fin_2$Note))^2)
RMSE_att_xg <- sqrt(mean((data_test_att_fin_2$Note - data_test_att_fin_2$.pred)^2))
erreur_moy_abs_att_xg <- mean(data_test_att_fin_2$DifferenceAbs)
```

### Milieu

```{r}
all_data_milieu <- subset(Milieu, select = -c(nom, Poste, Club, Annee, Poste_global))
all_data_milieu <- na.omit(all_data_milieu, cols = "Note")

#Diviser en entrainement et test
set.seed(123)
data_split_mil <- initial_split(all_data_milieu, prop = 0.75, strata = Note)
data_train_mil <- training(data_split_mil)
data_test_mil <- testing(data_split_mil)

#Préparation des données 
variable_a_tester_xg <- c("Age","minJ","Apparences","But","PasseDecisive","Tirs","Dribbles","Passes_perc","moy_passes","centre_perc","interception","tacle","tirsBloques","driblesSubis","fautes","TaclesRecu")
recipe_xg_mil <- recipe(Note ~ ., data = data_train_mil) |>
  update_role(all_of(variable_a_tester_xg), new_role = "predictor") |>
  step_normalize(all_predictors())

xgb_model_mil <-
  boost_tree(
    trees = 1000,
    stop_iter=20,
    min_n = 1,
    tree_depth = tune(),
    learn_rate = tune()
  ) |>
  set_mode("regression") |>
  set_engine("xgboost")

xgb_wf_mil <- workflow() |>
  add_recipe(recipe_xg_mil) |>
  add_model(xgb_model_mil)

play_samples_cv_mil <- vfold_cv(data_train_mil,v=3,repeats=1,strata="Note")

xgb_grid <- expand.grid(tree_depth=c(1,2,3,4,5),learn_rate=c(0.0205,0.0210, 0.215,0.220))

xgb_3fold_mil <- xgb_wf_mil |>
  tune_grid(resamples=play_samples_cv_mil,grid=xgb_grid,
            metrics=metric_set(mae))

xgb_3fold_mil |> autoplot()

best_par_mil <- xgb_3fold_mil |>
  select_best()

final_xgb_mil <- xgb_wf_mil |> 
  finalize_workflow(best_par_mil) |>
  fit(data = data_train_mil)

pred_mil <- final_xgb_mil |>
  predict(new_data=data_test_mil)


data_test_mil_fin <- data_test_mil |> select(Note)
data_test_mil_fin_2 <- cbind(pred_mil, data_test_mil_fin)

data_test_mil_fin_2$Difference <- data_test_mil_fin_2$Note - data_test_mil_fin_2$.pred
data_test_mil_fin_2$DifferenceAbs <- abs(data_test_mil_fin_2$Note - data_test_mil_fin_2$.pred)


# Calculer la médiane et les intervalles de confiance
median_diff_mil <- median(data_test_mil_fin_2$Difference)
ci_low_mil <- quantile(data_test_mil_fin_2$Difference, 0.025)
ci_high_mil <- quantile(data_test_mil_fin_2$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
gg_plot_mil <- ggplot(data_test_mil_fin_2, aes(x = rownames(data_test_mil_fin_2), y = Difference, color = Note)) +
  geom_point() +
  geom_hline(yintercept = median_diff_mil, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low_mil, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high_mil, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction XGboost sur Milieu",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

gg_plot_mil

R2_mil_xg <- 1 - sum((data_test_mil_fin_2$Note - data_test_mil_fin_2$.pred)^2) / sum((data_test_mil_fin_2$Note - mean(data_test_mil_fin_2$Note))^2)
RMSE_mil_xg <- sqrt(mean((data_test_mil_fin_2$Note - data_test_mil_fin_2$.pred)^2))
erreur_moy_abs_mil_xg <- mean(data_test_mil_fin_2$DifferenceAbs)
```

### Défenseur

```{r}
all_data_defenseur <- subset(Defenseur, select = -c(nom, Poste, Club, Annee, Poste_global))
all_data_defenseur <- na.omit(all_data_defenseur, cols = "Note")

#Diviser en entrainement et test
set.seed(123)
data_split_def <- initial_split(all_data_defenseur, prop = 0.75, strata = Note)
data_train_def <- training(data_split_def)
data_test_def <- testing(data_split_def)

#Préparation des données 
variable_a_tester_xg <- c("Age","minJ","Apparences","But","PasseDecisive","Tirs","Dribbles","Passes_perc","moy_passes","centre_perc","interception","tacle","tirsBloques","driblesSubis","fautes","TaclesRecu")
recipe_xg_def <- recipe(Note ~ ., data = data_train_def) |>
  update_role(all_of(variable_a_tester_xg), new_role = "predictor") |>
  step_normalize(all_predictors())

xgb_model_def <-
  boost_tree(
    trees = 1000,
    stop_iter=20,
    min_n = 1,
    tree_depth = tune(),
    learn_rate = tune()
  ) |>
  set_mode("regression") |>
  set_engine("xgboost")

xgb_wf_def <- workflow() |>
  add_recipe(recipe_xg_def) |>
  add_model(xgb_model_def)

play_samples_cv_def <- vfold_cv(data_train_def,v=3,repeats=1,strata="Note")

xgb_grid <- expand.grid(tree_depth=c(1,2,3,4,5),learn_rate=c(0.0205,0.0210, 0.215,0.220))

xgb_3fold_def <- xgb_wf_def |>
  tune_grid(resamples=play_samples_cv_def,grid=xgb_grid,
            metrics=metric_set(mae))

xgb_3fold_def |> autoplot()

best_par_def <- xgb_3fold_def |>
  select_best()

final_xgb_def <- xgb_wf_def |> 
  finalize_workflow(best_par_def) |>
  fit(data = data_train_def)

pred_def <- final_xgb_def |>
  predict(new_data=data_test_def)


data_test_def_fin <- data_test_def |> select(Note)
data_test_def_fin_2 <- cbind(pred_def, data_test_def_fin)

data_test_def_fin_2$Difference <- data_test_def_fin_2$Note - data_test_def_fin_2$.pred
data_test_def_fin_2$DifferenceAbs <- abs(data_test_def_fin_2$Note - data_test_def_fin_2$.pred)


# Calculer la médiane et les intervalles de confiance
median_diff_def <- median(data_test_def_fin_2$Difference)
ci_low_def <- quantile(data_test_def_fin_2$Difference, 0.025)
ci_high_def <- quantile(data_test_def_fin_2$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
gg_plot_def <- ggplot(data_test_def_fin_2, aes(x = rownames(data_test_def_fin_2), y = Difference, color = Note)) +
  geom_point() +
  geom_hline(yintercept = median_diff_def, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low_def, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high_def, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction XGboost sur Défenseur",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

gg_plot_def

R2_def_xg <- 1 - sum((data_test_def_fin_2$Note - data_test_def_fin_2$.pred)^2) / sum((data_test_def_fin_2$Note - mean(data_test_def_fin_2$Note))^2)
RMSE_def_xg <- sqrt(mean((data_test_def_fin_2$Note - data_test_def_fin_2$.pred)^2))
erreur_moy_abs_def_xg <- mean(data_test_def_fin_2$DifferenceAbs)

```

### Gardien

```{r}
all_data_gardien <- subset(Gardien, select = -c(nom, Poste, Club, Annee, Poste_global, tirsBloques))
all_data_gardien <- na.omit(all_data_gardien, cols = "Note")

#Diviser en entrainement et test
set.seed(123)
data_split_gar <- initial_split(all_data_gardien, prop = 0.75, strata = Note)
data_train_gar <- training(data_split_gar)
data_test_gar <- testing(data_split_gar)

#Préparation des données 
variable_a_tester_xg <- c("Age","minJ","Apparences","But","PasseDecisive","Tirs","Dribbles","Passes_perc","moy_passes","centre_perc","interception","tacle","driblesSubis","fautes","TaclesRecu")
recipe_xg_gar <- recipe(Note ~ ., data = data_train_gar) |>
  update_role(all_of(variable_a_tester_xg), new_role = "predictor") |>
  step_normalize(all_predictors())

xgb_model_gar <-
  boost_tree(
    trees = 1000,
    stop_iter=20,
    min_n = 1,
    tree_depth = tune(),
    learn_rate = tune()
  ) |>
  set_mode("regression") |>
  set_engine("xgboost")

xgb_wf_gar <- workflow() |>
  add_recipe(recipe_xg_gar) |>
  add_model(xgb_model_gar)

play_samples_cv_gar <- vfold_cv(data_train_gar,v=3,repeats=1,strata="Note")

xgb_grid <- expand.grid(tree_depth=c(1,2,3,4,5),learn_rate=c(0.0205,0.0210, 0.215,0.220))

xgb_3fold_gar <- xgb_wf_gar |>
  tune_grid(resamples=play_samples_cv_gar,grid=xgb_grid,
            metrics=metric_set(mae))

xgb_3fold_gar |> autoplot()

best_par_gar <- xgb_3fold_gar |>
  select_best()

final_xgb_gar <- xgb_wf_gar |> 
  finalize_workflow(best_par_gar) |>
  fit(data = data_train_gar)

pred_gar <- final_xgb_gar |>
  predict(new_data=data_test_gar)


data_test_gar_fin <- data_test_gar |> select(Note)
data_test_gar_fin_2 <- cbind(pred_gar, data_test_gar_fin)

data_test_gar_fin_2$Difference <- data_test_gar_fin_2$Note - data_test_gar_fin_2$.pred
data_test_gar_fin_2$DifferenceAbs <- abs(data_test_gar_fin_2$Note - data_test_gar_fin_2$.pred)


# Calculer la médiane et les intervalles de confiance
median_diff_gar <- median(data_test_gar_fin_2$Difference)
ci_low_gar <- quantile(data_test_gar_fin_2$Difference, 0.025)
ci_high_gar <- quantile(data_test_gar_fin_2$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
gg_plot_gar <- ggplot(data_test_gar_fin_2, aes(x = rownames(data_test_gar_fin_2), y = Difference, color = Note)) +
  geom_point() +
  geom_hline(yintercept = median_diff_gar, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low_gar, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high_gar, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction XGboost sur Gardien",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

gg_plot_gar

R2_gar_xg <- 1 - sum((data_test_gar_fin_2$Note - data_test_gar_fin_2$.pred)^2) / sum((data_test_gar_fin_2$Note - mean(data_test_gar_fin_2$Note))^2)
RMSE_gar_xg <- sqrt(mean((data_test_gar_fin_2$Note - data_test_gar_fin_2$.pred)^2))
erreur_moy_abs_gar_xg <- mean(data_test_gar_fin_2$DifferenceAbs)

```

### Total

```{r}
all_data_xg <- subset(all_data, select = -c(nom, Poste, Club, Annee, Poste_global))
all_data_xg <- na.omit(all_data_xg, cols = "Note")

#Diviser en entrainement et test
set.seed(123)
data_split <- initial_split(all_data_xg, prop = 0.65, strata = Note)
data_train <- training(data_split)
data_test <- testing(data_split)

#Préparation des données 
variable_a_tester_xg <- c("Age","minJ","Apparences","But","PasseDecisive","Tirs","Dribbles","Passes_perc","moy_passes","centre_perc","interception","tacle","tirsBloques","driblesSubis","fautes","TaclesRecu")
recipe_xg <- recipe(Note ~ ., data = data_train) |>
  update_role(all_of(variable_a_tester_xg), new_role = "predictor") |>
  step_normalize(all_predictors())

xgb_model <-
  boost_tree(
    trees = 1000,
    stop_iter=20,
    min_n = 1,
    tree_depth = tune(),
    learn_rate = tune()
  ) |>
  set_mode("regression") |>
  set_engine("xgboost")

xgb_wf <- workflow() |>
  add_recipe(recipe_xg) |>
  add_model(xgb_model)

play_samples_cv <- vfold_cv(data_train,v=3,repeats=1,strata="Note")

xgb_grid <- expand.grid(tree_depth=c(1,2,3,4,5),learn_rate=c(0.0205,0.0210, 0.215,0.220))

xgb_3fold <- xgb_wf |>
  tune_grid(resamples=play_samples_cv,grid=xgb_grid,
            metrics=metric_set(mae))

xgb_3fold |> autoplot()

best_par <- xgb_3fold |>
  select_best()

final_xgb <- xgb_wf |> 
  finalize_workflow(best_par) |>
  fit(data = data_train)

pred <- final_xgb |>
  predict(new_data=data_test)


data_test_fin <- data_test |> select(Note)
data_test_fin_2 <- cbind(pred, data_test_fin)

data_test_fin_2$Difference <- data_test_fin_2$Note - data_test_fin_2$.pred
data_test_fin_2$DifferenceAbs <- abs(data_test_fin_2$Note - data_test_fin_2$.pred)



# Calculer la médiane et les intervalles de confiance
median_diff <- median(data_test_fin_2$Difference)
ci_low <- quantile(data_test_fin_2$Difference, 0.025)
ci_high <- quantile(data_test_fin_2$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
gg_plot <- ggplot(data_test_fin_2, aes(x = rownames(data_test_fin_2), y = Difference, color = Note)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction XGboost sur population",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

gg_plot
R2_tot_xg <- 1 - sum((data_test_fin_2$Note - data_test_fin_2$.pred)^2) / sum((data_test_fin_2$Note - mean(data_test_fin_2$Note))^2)
RMSE_tot_xg <- sqrt(mean((data_test_fin_2$Note - data_test_fin_2$.pred)^2))
erreur_moy_abs_tot_xg <- mean(data_test_fin_2$DifferenceAbs)
```

Nous avons tester pour chaque post et pour la population totale XGboost on va venir faire un tableau recap prenant :

-   Le R2 par model

-   Le RMSE

-   La différence absolu moyenne = Moyenne ( \| Note - note.pred\| )

### b) Random Forest

#### Total

```{r}
library(ranger)
library(caret)
library(tidymodels)
library(ggplot2)

# Définir la graine pour la reproductibilité
set.seed(123)

# Séparation des données en ensemble d'entraînement et ensemble de test
data_split <- initial_split(all_data, prop = 0.8, strata = Note)
data_train <- training(data_split)
data_test <- testing(data_split)

# Supprimer les colonnes non pertinentes
data_train <- subset(data_train, select = -c(nom, Poste, Club, Annee, Poste_global))
data_train <- na.omit(data_train, cols = "Note")

data_test <- subset(data_test, select = -c(nom, Poste, Club, Annee, Poste_global))
data_test <- na.omit(data_test, cols = "Note")

# Recherche du meilleur mtry par validation croisée
pargrid_regression <- expand.grid(mtry = 1:16,
                                  splitrule = "variance",
                                  min.node.size = 1)

# Définir le schéma de validation croisée
ctrl <- trainControl(method = "cv", number = 5)

# Entraîner le modèle avec validation croisée
rf_model <- train(Note ~ ., 
                  data = data_train, 
                  method = "ranger", 
                  trControl = ctrl, 
                  tuneGrid = pargrid_regression)

# Afficher les résultats de la validation croisée
print(rf_model)

# Tracer la performance en fonction de mtry
ggplot(rf_model$results) +
  geom_line(aes(x = mtry, y = RMSE, color = "RMSE"), linetype = "solid") +
  geom_line(aes(x = mtry, y = Rsquared, color = "Rsquared"), linetype = "dashed") +
  labs(title = "Performance du Random Forest en fonction de mtry",
       x = "mtry",
       y = "Métrique") +
  scale_color_manual(values = c("blue", "red"),
                     labels = c("RMSE", "Rsquared"))

# Sélectionner le modèle optimal
best_mtry <- rf_model$bestTune$mtry

# Entraîner le modèle final avec le meilleur mtry
final_rf_model <- ranger(Note ~ ., 
                         data = data_train, 
                         mtry = best_mtry)

# Prédiction sur l'ensemble de test
predictions <- predict(final_rf_model, data = data_test)$predictions


# Calculer d'autres métriques d'évaluation
RMSE_tot_rf <- sqrt(mean((data_test$Note - predictions)^2))
R2_tot_rf <- 1 - sum((data_test$Note - predictions)^2) / sum((data_test$Note - mean(data_test$Note))^2)
erreur_moy_abs_tot_rf <- mean(abs(data_test$Note - predictions))

# Créer le dataframe de comparaison
comparison_rf <- data.frame(
  Actual = data_test$Note,
  Predicted = predictions,
  Residuals = data_test$Note - predictions,
  DifferenceAbs = abs(data_test$Note - predictions)
  
)



# Calculer la médiane et les intervalles de confiance
median_diff <- median(comparison_rf$Residuals)
ci_low <- quantile(comparison_rf$Residuals, 0.025)
ci_high <- quantile(comparison_rf$Residuals, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
ggplot(comparison_rf, aes(x = rownames(comparison_rf), y = Residuals, color = Actual)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5) + 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5) +   labs(title = "Prédiction Random Forest sur population",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

# Affichage des métriques
print(paste("RMSE :", RMSE))
print(paste("R-squared :", R2))
print(paste("Erreur absolue moyenne :", mean_absolute_diff))
```

### c) Régression linéaire

#### Total

```{r}
#Division en jeu d'entraienement 

set.seed(123)
data_split <- initial_split(all_data, prop = 0.8, strata = Note)
data_train <- training(data_split)
data_test <- testing(data_split)

#### Mise en place des modèles sans sélection de poste ####
lm_rec <- recipe(Note ~ ., data = data_train)

lm_model <- linear_reg() |>
  set_engine("lm") |>
  set_mode("regression")

lm_wf <- workflow() |>
  add_model(lm_model) |>
  add_recipe(lm_rec)

lm_fit <- lm_wf |>
  fit(data=data_train)


lm_fit |>
  tidy()

lm_fit |>
  glance()

# autres méthodes avec lm, on obtient des résultats similaires
reg <- lm(Note ~ .,data=data_train)
summary(reg)


data_train <- subset(data_train, select = -c(nom, Poste, Club, Annee, Poste_global))
data_train <- na.omit(data_train, cols = "Note")

data_test <- subset(data_test, select = -c(nom, Poste, Club, Annee, Poste_global))
data_test <- na.omit(data_test, cols = "Note")


reg <- lm(Note ~ .,data=data_train)
summary(reg)


predictions_lin <- predict(reg, new_data = data_test)
actual_values <- data_test$Note  

comparison_lin <- data.frame(Actual = actual_values, Predicted = predictions_lin)
residuals_lin <- actual_values - predictions_lin

comparison_lin <- data.frame(
  Actual = actual_values,
  Predicted = predictions_lin,
  Residuals = residuals_lin
)

colnames(comparison_lin) <- c("Actual", "Predicted", "Residuals")

comparison_lin$Difference <- comparison_lin$Actual - comparison_lin$Predicted
comparison_lin$DifferenceAbs <- abs(comparison_lin$Actual - comparison_lin$Predicted)




# Calculer la médiane et les intervalles de confiance
median_diff <- median(comparison_lin$Difference)
ci_low <- quantile(comparison_lin$Difference, 0.025)
ci_high <- quantile(comparison_lin$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
ggplot(comparison_lin, aes(x = rownames(comparison_lin), y = Residuals, color = Actual)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction Regréssion linéaire sur population",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

RMSE_reg_tot <- sqrt(mean(comparison_lin$Residuals^2))
R2_reg_tot <- 1 - sum((comparison_lin$Actual - comparison_lin$Predicted)^2) / sum((comparison_lin$Actual - mean(comparison_lin$Predicted))^2)
erreur_moy_abs_tot_reg <- mean(comparison_lin$DifferenceAbs)
```

#### Attaquant

```{r}
#### Mise en place des modèles en sélectionnant le poste, exemple de l'attaquant ####
set.seed(123)
data_split <- initial_split(all_data, prop = 0.8, strata = Note)
data_train <- training(data_split)
data_test <- testing(data_split)

all_data_poste_train <- data_train |> filter(Poste_global == "Attaquant")
all_data_poste_train <- subset(all_data_poste_train, select = -c(nom, Poste, Club, Annee, Poste_global))
all_data_poste_train <- na.omit(all_data_poste_train, cols = "Note")

all_data_poste_test <- data_test |> filter(Poste_global == "Attaquant")
all_data_poste_test <- subset(all_data_poste_test, select = -c(nom, Poste, Club, Annee, Poste_global))
all_data_poste_test <- na.omit(all_data_poste_test, cols = "Note")


reg <- lm(Note ~ .,data=all_data_poste_train)
summary(reg)


predictions_poste_lin_att <- predict(lm_fit, new_data = all_data_poste_test)
actual_values <- all_data_poste_test$Note  # Remplacez "Note" par le nom de votre variable dépendante
comparison_poste_lin_att <- data.frame(Actual = actual_values, Predicted = predictions_poste_lin_att)
residuals_lin_att <- actual_values - predictions_poste_lin_att

comparison_poste_lin_att <- data.frame(
  Actual = actual_values,
  Predicted = predictions_poste_lin_att,
  Residuals = residuals_lin_att
)

colnames(comparison_poste_lin_att) <- c("Actual", "Predicted", "Residuals")

comparison_poste_lin_att$Difference <- comparison_poste_lin_att$Actual - comparison_poste_lin_att$Predicted
comparison_poste_lin_att$DifferenceAbs <- abs(comparison_poste_lin_att$Actual - comparison_poste_lin_att$Predicted)




# Calculer la médiane et les intervalles de confiance
median_diff <- median(comparison_poste_lin_att$Difference)
ci_low <- quantile(comparison_poste_lin_att$Difference, 0.025)
ci_high <- quantile(comparison_poste_lin_att$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
ggplot(comparison_poste_lin_att, aes(x = rownames(comparison_poste_lin_att), y = Residuals, color = Actual)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction Regréssion linéaire sur population",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

RMSE_reg_att <- sqrt(mean(comparison_poste_lin_att$Residuals^2))
R2_reg_att <- 1 - sum((comparison_poste_lin_att$Actual - comparison_poste_lin_att$Predicted)^2) / sum((comparison_poste_lin_att$Actual - mean(comparison_poste_lin_att$Predicted))^2)
erreur_moy_abs_att_reg <- mean(comparison_poste_lin_att$DifferenceAbs)

```

### d) Régression Lasso

#### Total

```{r}
# Régression LASSO avec validation croisée

lasso_model <- linear_reg() |>
  set_engine("glmnet") |>
  set_mode("regression") |>
  set_args(penalty = tune(), mixture = 1)

lasso_wf <- workflow() |> 
  add_model(lasso_model) |> 
  add_formula(Note ~ .)

folds <- vfold_cv(data_train, v=5, strata = "Note")

lambda_grid <- grid_regular(penalty(range = c(-5, 2)), levels = 100)
lambda_grid$penalty

lasso_cv <- lasso_wf |> 
  tune_grid(resamples = folds, grid = lambda_grid, metrics = metric_set(rsq))


res <- lasso_cv |>
  collect_metrics()


res$mean


lasso_cv |>
  collect_metrics() |>
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")

# On sélectionne le lambda qui minimise le risque estimé par VC

best_rsq <- lasso_cv |>
  select_best(metric="rsq")
best_rsq$penalty

# On relance (entraine) la régression LASSO avec ce "meilleur" lambda sur l'ensemble du jeu de données pour obtenir le "meilleur" prédicteur LASSO

final_wf <- finalize_workflow(lasso_wf,best_rsq)
print(final_wf)

final_lasso <- final_wf |>
  fit(data_train)

final_lasso |> tidy()


predictions_lasso <- predict(final_lasso, new_data = data_test)
comparison_lasso <- data.frame(Actual = actual_values, Predicted = predictions_lasso)
residuals_lasso <- actual_values - predictions_lasso

comparison_lasso <- data.frame(
  Actual = actual_values,
  Predicted = predictions_lasso,
  Residuals = residuals_lasso
)
colnames(comparison_lasso) <- c("Actual", "Predicted", "Residuals")


comparison_lasso$Difference <- comparison_lasso$Actual - comparison_lasso$Predicted
comparison_lasso$DifferenceAbs <- abs(comparison_lasso$Actual - comparison_lasso$Predicted)




# Calculer la médiane et les intervalles de confiance
median_diff <- median(comparison_lasso$Difference)
ci_low <- quantile(comparison_lasso$Difference, 0.025)
ci_high <- quantile(comparison_lasso$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
ggplot(comparison_lasso, aes(x = rownames(comparison_lasso), y = Residuals, color = Actual)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction Regréssion LASSO sur population",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

RMSE_regLASSO_tot <- sqrt(mean(comparison_lasso$Residuals^2))
R2_regLASSO_tot <- 1 - sum((comparison_lasso$Actual - comparison_lasso$Predicted)^2) / sum((comparison_lasso$Actual - mean(comparison_lasso$Predicted))^2)
erreur_moy_abs_tot_regLASSO <- mean(comparison_lasso$DifferenceAbs)

```

#### Attaquant

```{r}
lasso_att_model <- linear_reg() |>
  set_engine("glmnet") |>
  set_mode("regression") |>
  set_args(penalty = tune(), mixture = 1)

lasso_att_wf <- workflow() |> 
  add_model(lasso_att_model) |> 
  add_formula(Note ~ .)

folds <- vfold_cv(all_data_poste_train, v=5, strata = "Note")

lambda_grid <- grid_regular(penalty(range = c(-5, 2)), levels = 100)
lambda_grid$penalty

lasso_att_cv <- lasso_att_wf |> 
  tune_grid(resamples = folds, grid = lambda_grid, metrics = metric_set(rsq))


res <- lasso_att_cv |>
  collect_metrics()


res$mean


lasso_att_cv |>
  collect_metrics() |>
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")

# On sélectionne le lambda qui minimise le risque estimé par VC

best_rsq <- lasso_att_cv |>
  select_best(metric="rsq")
best_rsq$penalty

# On relance (entraine) la régression lasso_att avec ce "meilleur" lambda sur l'ensemble du jeu de données pour obtenir le "meilleur" prédicteur lasso_att

final_wf <- finalize_workflow(lasso_att_wf,best_rsq)
print(final_wf)

final_lasso_att <- final_wf |>
  fit(all_data_poste_train)

final_lasso_att |> tidy()


predictions_poste_lasso_att <- predict(final_lasso_att, new_data = all_data_poste_test)
comparison_poste_lasso_att <- data.frame(Actual = actual_values, Predicted = predictions_poste_lasso_att)
residuals_lasso_att <- actual_values - predictions_poste_lasso_att

comparison_poste_lasso_att <- data.frame(
  Actual = actual_values,
  Predicted = predictions_poste_lasso_att,
  Residuals = residuals_lasso_att
)
colnames(comparison_poste_lasso_att) <- c("Actual", "Predicted", "Residuals")

comparison_poste_lasso_att$Difference <- comparison_poste_lasso_att$Actual - comparison_poste_lasso_att$Predicted
comparison_poste_lasso_att$DifferenceAbs <- abs(comparison_poste_lasso_att$Actual - comparison_poste_lasso_att$Predicted)




# Calculer la médiane et les intervalles de confiance
median_diff <- median(comparison_poste_lasso_att$Difference)
ci_low <- quantile(comparison_poste_lasso_att$Difference, 0.025)
ci_high <- quantile(comparison_poste_lasso_att$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
ggplot(comparison_poste_lasso_att, aes(x = rownames(comparison_poste_lasso_att), y = Difference, color = Actual)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction Regréssion LASSO sur population",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

RMSE_regLASSO_att <- sqrt(mean(comparison_poste_lasso_att$Residuals^2))
R2_regLASSO_att <- 1 - sum((comparison_poste_lasso_att$Actual - comparison_poste_lasso_att$Predicted)^2) / sum((comparison_poste_lasso_att$Actual - mean(comparison_poste_lasso_att$Predicted))^2)
erreur_moy_abs_att_regLASSO <- mean(comparison_poste_lasso_att$DifferenceAbs)

```

### e) Régression Ridge

#### Total

```{r}
# Régression RIDGE avec validation croisée

ridge_model <- linear_reg() |>
  set_engine("glmnet") |>
  set_mode("regression") |>
  set_args(penalty = tune(), mixture = 0)

ridge_wf <- workflow() |> 
  add_model(ridge_model) |> 
  add_formula(Note ~ .)


ridge_cv <- ridge_wf |> 
  tune_grid(resamples = folds, grid = lambda_grid, metrics = metric_set(rsq))


res <- ridge_cv |>
  collect_metrics()


res$mean


ridge_cv |>
  collect_metrics() |>
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")

# On sélectionne le lambda qui minimise le risque estimé par VC

best_rsq <- ridge_cv |>
  select_best(metric="rsq")
best_rsq$penalty

# On relance (entraine) la régression ridge avec ce "meilleur" lambda sur l'ensemble du jeu de données pour obtenir le "meilleur" prédicteur ridge

final_wf <- finalize_workflow(ridge_wf,best_rsq)
print(final_wf)

final_ridge <- final_wf |>
  fit(data_train)

final_ridge |> tidy()


predictions_ridge <- predict(final_ridge, new_data = data_test)
comparison_ridge <- data.frame(Actual = actual_values, Predicted = predictions_ridge)
residuals_ridge <- actual_values - predictions_ridge

comparison_ridge <- data.frame(
  Actual = actual_values,
  Predicted = predictions_ridge,
  Residuals = residuals_ridge
)
colnames(comparison_ridge) <- c("Actual", "Predicted", "Residuals")

comparison_ridge$Difference <- comparison_ridge$Actual - comparison_ridge$Predicted
comparison_ridge$DifferenceAbs <- abs(comparison_ridge$Actual - comparison_ridge$Predicted)




# Calculer la médiane et les intervalles de confiance
median_diff <- median(comparison_ridge$Difference)
ci_low <- quantile(comparison_ridge$Difference, 0.025)
ci_high <- quantile(comparison_ridge$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
ggplot(comparison_ridge, aes(x = rownames(comparison_ridge), y = Residuals, color = Actual)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction Regréssion RIDGE sur population",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

RMSE_regRIDGE_tot <- sqrt(mean(comparison_ridge$Residuals^2))
R2_regRIDGE_tot <- 1 - sum((comparison_ridge$Actual - comparison_ridge$Predicted)^2) / sum((comparison_ridge$Actual - mean(comparison_ridge$Predicted))^2)
erreur_moy_abs_tot_regRIDGE <- mean(comparison_ridge$DifferenceAbs)
```

#### Attaquant

```{r}
ridge_att_model <- linear_reg() |>
  set_engine("glmnet") |>
  set_mode("regression") |>
  set_args(penalty = tune(), mixture = 0)

ridge_att_wf <- workflow() |> 
  add_model(ridge_att_model) |> 
  add_formula(Note ~ .)


ridge_att_cv <- ridge_att_wf |> 
  tune_grid(resamples = folds, grid = lambda_grid, metrics = metric_set(rsq))


res <- ridge_att_cv |>
  collect_metrics()


res$mean


ridge_att_cv |>
  collect_metrics() |>
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")

# On sélectionne le lambda qui minimise le risque estimé par VC

best_rsq <- ridge_att_cv |>
  select_best(metric="rsq")
best_rsq$penalty

# On relance (entraine) la régression ridge_att avec ce "meilleur" lambda sur l'ensemble du jeu de données pour obtenir le "meilleur" prédicteur ridge_att

final_wf <- finalize_workflow(ridge_att_wf,best_rsq)
print(final_wf)

final_ridge_att <- final_wf |>
  fit(all_data_poste_train)

final_ridge_att |> tidy()


predictions_poste_ridge_att <- predict(final_ridge_att, new_data = all_data_poste_test)
comparison_poste_ridge_att <- data.frame(Actual = actual_values, Predicted = predictions_poste_ridge_att)
residuals_ridge_att <- actual_values - predictions_poste_ridge_att

comparison_poste_ridge_att <- data.frame(
  Actual = actual_values,
  Predicted = predictions_poste_ridge_att,
  Residuals = residuals_ridge_att
)
colnames(comparison_poste_ridge_att) <- c("Actual", "Predicted", "Residuals")

comparison_poste_ridge_att$Difference <- comparison_poste_ridge_att$Actual - comparison_poste_ridge_att$Predicted
comparison_poste_ridge_att$DifferenceAbs <- abs(comparison_poste_ridge_att$Actual - comparison_poste_ridge_att$Predicted)




# Calculer la médiane et les intervalles de confiance
median_diff <- median(comparison_poste_ridge_att$Difference)
ci_low <- quantile(comparison_poste_ridge_att$Difference, 0.025)
ci_high <- quantile(comparison_poste_ridge_att$Difference, 0.975)

# Créer le plot ggplot2 avec médiane et intervalles de confiance
ggplot(comparison_poste_ridge_att, aes(x = rownames(comparison_poste_ridge_att), y = Difference, color = Actual)) +
  geom_point() +
  geom_hline(yintercept = median_diff, linetype = "dashed", color = "black", size = 1) +
  geom_hline(yintercept = ci_low, linetype = "dashed", color = "black", size = 0.5)+ 
  geom_hline(yintercept = ci_high, linetype = "dashed", color = "black", size = 0.5)+ 
  labs(title = "Prédiction Regréssion RIDGE sur Attaquant",
       x = "Individu",
       y = "Différence") +
  scale_colour_gradientn(colours = terrain.colors(10)) +
  theme_classic() 

RMSE_regRIDGE_att <- sqrt(mean(comparison_poste_ridge_att$Residuals^2))
R2_regRIDGE_att <- 1 - sum((comparison_poste_ridge_att$Actual - comparison_poste_ridge_att$Predicted)^2) / sum((comparison_poste_ridge_att$Actual - mean(comparison_poste_ridge_att$Predicted))^2)
erreur_moy_abs_att_regRIDGE <- mean(comparison_poste_ridge_att$DifferenceAbs)
```

### g) Recap

```{r}
recap <- data.frame(
  Model = c("XG_att", "XG_mil", "XG_def", "XG_gar", "XG_tot", "Reg_tot","Reg_att", "Reg_LASSO","Reg_LASSO_att", "Reg_RIDGE", "Reg_RIDGE_att", "Rf_tot"),
  R2 = c(R2_att_xg, R2_mil_xg, R2_def_xg, R2_gar_xg, R2_tot_xg, R2_reg_tot,R2_reg_att, R2_regLASSO_tot,R2_regLASSO_att, R2_regRIDGE_tot, R2_regRIDGE_att, R2_tot_rf),
  RMSE = c(RMSE_att_xg, RMSE_mil_xg, RMSE_def_xg, RMSE_gar_xg, RMSE_tot_xg, RMSE_reg_tot,RMSE_reg_att, RMSE_regLASSO_tot,RMSE_regLASSO_att, RMSE_regRIDGE_tot, RMSE_regRIDGE_att, RMSE_tot_rf),
  DifMoyAbs = c(erreur_moy_abs_att_xg, erreur_moy_abs_mil_xg, erreur_moy_abs_def_xg, erreur_moy_abs_gar_xg, erreur_moy_abs_tot_xg, erreur_moy_abs_tot_reg,erreur_moy_abs_att_reg,erreur_moy_abs_att_regLASSO, erreur_moy_abs_tot_regLASSO, erreur_moy_abs_tot_regRIDGE, erreur_moy_abs_att_regRIDGE,erreur_moy_abs_tot_rf)
)

recap <- recap %>%
  mutate_at(vars(RMSE, R2, DifMoyAbs), ~ round(., 4))

print(recap)
```

## Conclusion de sélection de modèle

Pour conclure sur la sélection de modèle, dans notre cas va s'opérer sur la population totale ( c'est à dire l'ensemble des postes de chacun des joeueurs). On veut un modèle qui soit le plus puissant possible pour prédire la note de joeueurs évoluant sur différents postes.

Toutefois nous avons identifier quelques axes x'améliorations que l'on pourrait inclure à notre modèle pour le rendre légérement plus restrictif mais plus puissant :

-   Transformer les variables pour qu'elles représentente toutes la même unités de mesures ( Dans notre jeu de données la quasi-totalités des variables sont exprimés par % sur un match ou par moyenne par matchs à l'exception de trois ( Min Joués, But et passes décisives nous allons donc essyayer de transformer cela afin d'étudier les gains de précisions de ce dernier.

```{r}
test_data <- all_data |> mutate(MJ_match = minJ/Apparences,
                                But_match = (But/minJ)*90,
                                PasseDe_match = (PasseDecisive/minJ)*90)


```

```{r}
all_data_2 <- test_data |> filter(minJ >270)
all_data_2 <- all_data_2 |> filter(MJ_match > 45)
all_data_2 <- all_data_2 |> filter(Note >=6)
all_data_2 <- all_data_2 |> filter(Note <=8)

variable_a_tester_xg <- c("Age","MJ_match","But_match","PasseDe_match","Tirs","Dribbles","Passes_perc","moy_passes","centre_perc","interception","tacle","tirsBloques","driblesSubis","fautes","TaclesRecu")
```
